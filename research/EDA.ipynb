{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c203137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loaded rows: 2312\n",
      "\n",
      "ğŸ§ª Missing values:\n",
      "text         0\n",
      "intent       0\n",
      "topic        0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "from collections import Counter\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "INPUT_FILE = r\"C:\\Users\\ahmed\\Downloads\\pharmacy_checkpoint.jsonl\"\n",
    "OUTPUT_CLEAN = \"pharmacy_clean.csv\"\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "INTENT_COL = \"intent\"\n",
    "TOPIC_COL = \"topic\"\n",
    "SENTIMENT_COL = \"sentiment\"\n",
    "\n",
    "MIN_TEXT_LEN = 8\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "if INPUT_FILE.endswith(\".jsonl\"):\n",
    "    rows = []\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                rows.append(json.loads(line))\n",
    "    df = pd.DataFrame(rows)\n",
    "else:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "print(f\"ğŸ“¥ Loaded rows: {len(df)}\")\n",
    "\n",
    "# =========================\n",
    "# BASIC SANITY CHECK\n",
    "# =========================\n",
    "print(\"\\nğŸ§ª Missing values:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d61fab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ‚ï¸ Short texts (<8 chars): 0\n",
      "\n",
      "ğŸ” Duplicate analysis:\n",
      "Total rows   : 2312\n",
      "Unique texts : 2284\n",
      "Duplicate %  : 1.21%\n",
      "\n",
      "ğŸ” Repeated sentences: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŸ</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù„ÙŠ Ø¨ØªØ´ØªØ±ÙŠÙ‡Ø§ Ù…Ù† Ø§Ù„ØµÙŠØ¯...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø·ÙˆÙŠÙ„ Ø£ÙˆÙŠØŒ Ù…ÙÙŠØ´ Ù†Ø¸Ø§Ù… ÙÙŠ Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ©.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Ø¥ÙŠÙ‡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯ÙØ¹ Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…ØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ØºØ§Ù„ÙŠØ© Ø£ÙˆÙŠØŒ ÙÙŠÙ† Ø§Ù„ØªØ®ÙÙŠØ¶Ø§ØªØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>Ø³Ø¹Ø± (Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡) ÙƒØ§Ù…ØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙ…!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Ø¹Ù†Ø¯Ùƒ ÙÙŠØªØ§Ù…ÙŠÙ†Ø§Øª Ù„ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø¹Ø©ØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† ØµØ­Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† ØµØ­ÙŠ Ù„Ù„Ø§Ø¯ÙˆÙŠØ©ØŸ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  count\n",
       "1623                           Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŸ     13\n",
       "1614  Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù„ÙŠ Ø¨ØªØ´ØªØ±ÙŠÙ‡Ø§ Ù…Ù† Ø§Ù„ØµÙŠØ¯...      3\n",
       "321           Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø·ÙˆÙŠÙ„ Ø£ÙˆÙŠØŒ Ù…ÙÙŠØ´ Ù†Ø¸Ø§Ù… ÙÙŠ Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ©.      2\n",
       "267                        Ø¥ÙŠÙ‡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¯ÙØ¹ Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…ØŸ      2\n",
       "41              Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ØºØ§Ù„ÙŠØ© Ø£ÙˆÙŠØŒ ÙÙŠÙ† Ø§Ù„ØªØ®ÙÙŠØ¶Ø§ØªØŸ      2\n",
       "1242                              Ø³Ø¹Ø± (Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡) ÙƒØ§Ù…ØŸ      2\n",
       "1342                                         Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙ…!      2\n",
       "1560                     Ø¹Ù†Ø¯Ùƒ ÙÙŠØªØ§Ù…ÙŠÙ†Ø§Øª Ù„ØªÙ‚ÙˆÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø¹Ø©ØŸ      2\n",
       "1604                       Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† ØµØ­Ù‰ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŸ      2\n",
       "1607                           Ø¹Ù†Ø¯Ù†Ø§ ØªØ£Ù…ÙŠÙ† ØµØ­ÙŠ Ù„Ù„Ø§Ø¯ÙˆÙŠØ©ØŸ      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ Intent conflicts: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, intent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Intent distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "Complaint    844\n",
       "Inquiry      791\n",
       "Praise       677\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Topic distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "availability      569\n",
       "delivery          514\n",
       "staff_behavior    396\n",
       "price             340\n",
       "insurance         302\n",
       "waiting_time      103\n",
       "prescription       88\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Sentiment distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative      828\n",
       "neutral       794\n",
       "positive      684\n",
       "frustrated      3\n",
       "mixed           2\n",
       "angry           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§¹ After cleaning:\n",
      "Rows left: 2284\n",
      "Unique texts: 2284\n",
      "\n",
      "ğŸ’¾ Clean dataset saved to: pharmacy_clean.csv\n",
      "\n",
      "â­ Dataset quality score: 98.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =========================\n",
    "# TEXT LENGTH CHECK\n",
    "# =========================\n",
    "df[\"text_len\"] = df[TEXT_COL].str.len()\n",
    "short_texts = df[df[\"text_len\"] < MIN_TEXT_LEN]\n",
    "\n",
    "print(f\"\\nâœ‚ï¸ Short texts (<{MIN_TEXT_LEN} chars): {len(short_texts)}\")\n",
    "\n",
    "# =========================\n",
    "# DUPLICATE ANALYSIS\n",
    "# =========================\n",
    "total_rows = len(df)\n",
    "unique_texts = df[TEXT_COL].nunique()\n",
    "\n",
    "print(\"\\nğŸ” Duplicate analysis:\")\n",
    "print(f\"Total rows   : {total_rows}\")\n",
    "print(f\"Unique texts : {unique_texts}\")\n",
    "print(f\"Duplicate %  : {(1 - unique_texts/total_rows) * 100:.2f}%\")\n",
    "\n",
    "dup_counts = (\n",
    "    df.groupby(TEXT_COL)\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "repeated_texts = dup_counts[dup_counts[\"count\"] > 1]\n",
    "\n",
    "print(f\"\\nğŸ” Repeated sentences: {len(repeated_texts)}\")\n",
    "display(repeated_texts.head(10))\n",
    "\n",
    "# =========================\n",
    "# LABEL CONFLICTS\n",
    "# =========================\n",
    "conflicts = (\n",
    "    df.groupby(TEXT_COL)[INTENT_COL]\n",
    "      .nunique()\n",
    "      .reset_index()\n",
    "      .query(f\"{INTENT_COL} > 1\")\n",
    ")\n",
    "\n",
    "print(f\"\\nâš ï¸ Intent conflicts: {len(conflicts)}\")\n",
    "display(conflicts.head(10))\n",
    "\n",
    "# =========================\n",
    "# DISTRIBUTIONS\n",
    "# =========================\n",
    "print(\"\\nğŸ“Š Intent distribution:\")\n",
    "display(df[INTENT_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Topic distribution:\")\n",
    "display(df[TOPIC_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Sentiment distribution:\")\n",
    "display(df[SENTIMENT_COL].value_counts())\n",
    "\n",
    "# =========================\n",
    "# CLEANING\n",
    "# =========================\n",
    "clean_df = df.copy()\n",
    "\n",
    "# Remove short texts\n",
    "clean_df = clean_df[clean_df[\"text_len\"] >= MIN_TEXT_LEN]\n",
    "\n",
    "# Remove conflicting texts\n",
    "clean_df = clean_df[~clean_df[TEXT_COL].isin(conflicts[TEXT_COL])]\n",
    "\n",
    "# Remove duplicates (keep first)\n",
    "clean_df = clean_df.drop_duplicates(subset=[TEXT_COL], keep=\"first\")\n",
    "\n",
    "clean_df_chunk_1 = clean_df.drop(columns=[\"text_len\"])\n",
    "\n",
    "print(\"\\nğŸ§¹ After cleaning:\")\n",
    "print(f\"Rows left: {len(clean_df)}\")\n",
    "print(f\"Unique texts: {clean_df[TEXT_COL].nunique()}\")\n",
    "\n",
    "# =========================\n",
    "# SAVE CLEAN DATA\n",
    "# =========================\n",
    "clean_df.to_csv(OUTPUT_CLEAN, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nğŸ’¾ Clean dataset saved to: {OUTPUT_CLEAN}\")\n",
    "\n",
    "# =========================\n",
    "# FINAL QUALITY SCORE\n",
    "# =========================\n",
    "quality_score = (\n",
    "    clean_df[TEXT_COL].nunique() / total_rows * 100\n",
    ")\n",
    "\n",
    "print(f\"\\nâ­ Dataset quality score: {quality_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a823ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loaded rows: 979\n",
      "\n",
      "ğŸ§ª Missing values:\n",
      "text         0\n",
      "intent       0\n",
      "topic        0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = r\"C:\\Users\\ahmed\\Downloads\\pharmacy_messages (1).csv\"\n",
    "OUTPUT_CLEAN = \"pharmacy_clean_2.csv\"\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "INTENT_COL = \"intent\"\n",
    "TOPIC_COL = \"topic\"\n",
    "SENTIMENT_COL = \"sentiment\"\n",
    "MIN_TEXT_LEN = 8\n",
    "\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"ğŸ“¥ Loaded rows: {len(df)}\")\n",
    "print(\"\\nğŸ§ª Missing values:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130ee91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ‚ï¸ Short texts (<8 chars): 0\n",
      "\n",
      "ğŸ” Duplicate analysis:\n",
      "Total rows   : 979\n",
      "Unique texts : 979\n",
      "Duplicate %  : 0.00%\n",
      "\n",
      "ğŸ” Repeated sentences: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ Intent conflicts: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, intent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Intent distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "Complaint    341\n",
       "Praise       324\n",
       "Inquiry      314\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Topic distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "delivery          434\n",
       "staff_behavior    309\n",
       "insurance         149\n",
       "waiting_time       87\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Sentiment distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    338\n",
       "positive    326\n",
       "neutral     315\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§¹ After cleaning:\n",
      "Rows left: 979\n",
      "Unique texts: 979\n",
      "\n",
      "ğŸ’¾ Clean dataset saved to: pharmacy_clean_2.csv\n",
      "\n",
      "â­ Dataset quality score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# TEXT LENGTH CHECK\n",
    "# =========================\n",
    "df[\"text_len\"] = df[TEXT_COL].str.len()\n",
    "short_texts = df[df[\"text_len\"] < MIN_TEXT_LEN]\n",
    "\n",
    "print(f\"\\nâœ‚ï¸ Short texts (<{MIN_TEXT_LEN} chars): {len(short_texts)}\")\n",
    "\n",
    "# =========================\n",
    "# DUPLICATE ANALYSIS\n",
    "# =========================\n",
    "total_rows = len(df)\n",
    "unique_texts = df[TEXT_COL].nunique()\n",
    "\n",
    "print(\"\\nğŸ” Duplicate analysis:\")\n",
    "print(f\"Total rows   : {total_rows}\")\n",
    "print(f\"Unique texts : {unique_texts}\")\n",
    "print(f\"Duplicate %  : {(1 - unique_texts/total_rows) * 100:.2f}%\")\n",
    "\n",
    "dup_counts = (\n",
    "    df.groupby(TEXT_COL)\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "repeated_texts = dup_counts[dup_counts[\"count\"] > 1]\n",
    "\n",
    "print(f\"\\nğŸ” Repeated sentences: {len(repeated_texts)}\")\n",
    "display(repeated_texts.head(10))\n",
    "\n",
    "# =========================\n",
    "# LABEL CONFLICTS\n",
    "# =========================\n",
    "conflicts = (\n",
    "    df.groupby(TEXT_COL)[INTENT_COL]\n",
    "      .nunique()\n",
    "      .reset_index()\n",
    "      .query(f\"{INTENT_COL} > 1\")\n",
    ")\n",
    "\n",
    "print(f\"\\nâš ï¸ Intent conflicts: {len(conflicts)}\")\n",
    "display(conflicts.head(10))\n",
    "\n",
    "# =========================\n",
    "# DISTRIBUTIONS\n",
    "# =========================\n",
    "print(\"\\nğŸ“Š Intent distribution:\")\n",
    "display(df[INTENT_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Topic distribution:\")\n",
    "display(df[TOPIC_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Sentiment distribution:\")\n",
    "display(df[SENTIMENT_COL].value_counts())\n",
    "\n",
    "# =========================\n",
    "# CLEANING\n",
    "# =========================\n",
    "clean_df = df.copy()\n",
    "\n",
    "# Remove short texts\n",
    "clean_df = clean_df[clean_df[\"text_len\"] >= MIN_TEXT_LEN]\n",
    "\n",
    "# Remove conflicting texts\n",
    "clean_df = clean_df[~clean_df[TEXT_COL].isin(conflicts[TEXT_COL])]\n",
    "\n",
    "# Remove duplicates (keep first)\n",
    "clean_df = clean_df.drop_duplicates(subset=[TEXT_COL], keep=\"first\")\n",
    "\n",
    "clean_df_chunk_2= clean_df.drop(columns=[\"text_len\"])\n",
    "\n",
    "print(\"\\nğŸ§¹ After cleaning:\")\n",
    "print(f\"Rows left: {len(clean_df)}\")\n",
    "print(f\"Unique texts: {clean_df[TEXT_COL].nunique()}\")\n",
    "\n",
    "# =========================\n",
    "# SAVE CLEAN DATA\n",
    "# =========================\n",
    "clean_df.to_csv(OUTPUT_CLEAN, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nğŸ’¾ Clean dataset saved to: {OUTPUT_CLEAN}\")\n",
    "\n",
    "# =========================\n",
    "# FINAL QUALITY SCORE\n",
    "# =========================\n",
    "quality_score = (\n",
    "    clean_df[TEXT_COL].nunique() / total_rows * 100\n",
    ")\n",
    "\n",
    "print(f\"\\nâ­ Dataset quality score: {quality_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbbcbcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Combined dataset:\n",
      "Total rows: 3263\n",
      "Columns: ['text', 'intent', 'topic', 'sentiment']\n",
      "\n",
      "                                                text   intent         topic  \\\n",
      "0  Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ© Ø¯ÙŠ Ø£Ø­Ø³Ù† ØµÙŠØ¯Ù„ÙŠØ© Ø´ÙØªÙ‡Ø§! ÙƒÙ„ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù…ÙˆØ¬...   Praise  availability   \n",
      "1  Ø£Ù†Ø§ Ø£Ø­Ø¨ Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ© Ø¯ÙŠ ÙƒØªÙŠØ±! ÙƒÙ„ Ù…Ø±Ø© Ø¨Ø¬ÙŠÙ„Ù‡Ø§ Ù„Ø§Ù‚Ù‰ Ùƒ...   Praise  availability   \n",
      "2  Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ© Ø¯ÙŠ Ø¬ÙˆÙ‡ Ø¹ÙŠÙ†ÙŠ! Ø¯Ø§ÙŠÙ…Ø§Ù‹ Ù…ØªÙˆÙØ±Ø© Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ù„...   Praise  availability   \n",
      "3                 Ù…Ø±Ø­Ø¨Ø§! Ù‡Ù„ Ù„Ø¯ÙŠÙƒÙ… Ø¯ÙˆØ§Ø¡ (Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡)ØŸ  Inquiry  availability   \n",
      "4                Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø´Ø±Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø¨Ø³Ø¹Ø± Ø£Ù‚Ù„ØŸ  Inquiry         price   \n",
      "\n",
      "  sentiment  \n",
      "0  positive  \n",
      "1  positive  \n",
      "2  positive  \n",
      "3   neutral  \n",
      "4   neutral  \n",
      "\n",
      "âœ… After removing duplicates from combined dataset:\n",
      "Total rows: 2284\n",
      "\n",
      "ğŸ’¾ Combined dataset saved to: pharmacy_combined.csv\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([clean_df_chunk_1, clean_df_chunk_2], ignore_index=True)\n",
    "\n",
    "print(f\"ğŸ“Š Combined dataset:\")\n",
    "print(f\"Total rows: {len(combined_df)}\")\n",
    "print(f\"Columns: {combined_df.columns.tolist()}\")\n",
    "print(f\"\\n{combined_df.head()}\")\n",
    "\n",
    "# Optional: Remove duplicates from combined dataset\n",
    "combined_df = combined_df.drop_duplicates(subset=[TEXT_COL], keep=\"first\")\n",
    "\n",
    "print(f\"\\nâœ… After removing duplicates from combined dataset:\")\n",
    "print(f\"Total rows: {len(combined_df)}\")\n",
    "\n",
    "# Save combined dataset\n",
    "combined_df.to_csv(\"pharmacy_combined.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nğŸ’¾ Combined dataset saved to: pharmacy_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452cd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ced0079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ‚ï¸ Short texts (<8 chars): 0\n",
      "\n",
      "ğŸ” Duplicate analysis:\n",
      "Total rows   : 2284\n",
      "Unique texts : 2284\n",
      "Duplicate %  : 0.00%\n",
      "\n",
      "ğŸ” Repeated sentences: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, count]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸ Intent conflicts: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, intent]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Intent distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "Complaint    842\n",
       "Inquiry      766\n",
       "Praise       676\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Topic distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "availability      567\n",
       "delivery          511\n",
       "staff_behavior    396\n",
       "price             337\n",
       "insurance         284\n",
       "waiting_time      102\n",
       "prescription       87\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Sentiment distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative      826\n",
       "neutral       769\n",
       "positive      683\n",
       "frustrated      3\n",
       "mixed           2\n",
       "angry           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§¹ After cleaning:\n",
      "Rows left: 2284\n",
      "Unique texts: 2284\n",
      "\n",
      "ğŸ’¾ Clean dataset saved to: pharmacy_clean_2.csv\n",
      "\n",
      "â­ Dataset quality score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# TEXT LENGTH CHECK\n",
    "# =========================\n",
    "df[\"text_len\"] = df[TEXT_COL].str.len()\n",
    "short_texts = df[df[\"text_len\"] < MIN_TEXT_LEN]\n",
    "\n",
    "print(f\"\\nâœ‚ï¸ Short texts (<{MIN_TEXT_LEN} chars): {len(short_texts)}\")\n",
    "\n",
    "# =========================\n",
    "# DUPLICATE ANALYSIS\n",
    "# =========================\n",
    "total_rows = len(df)\n",
    "unique_texts = df[TEXT_COL].nunique()\n",
    "\n",
    "print(\"\\nğŸ” Duplicate analysis:\")\n",
    "print(f\"Total rows   : {total_rows}\")\n",
    "print(f\"Unique texts : {unique_texts}\")\n",
    "print(f\"Duplicate %  : {(1 - unique_texts/total_rows) * 100:.2f}%\")\n",
    "\n",
    "dup_counts = (\n",
    "    df.groupby(TEXT_COL)\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "repeated_texts = dup_counts[dup_counts[\"count\"] > 1]\n",
    "\n",
    "print(f\"\\nğŸ” Repeated sentences: {len(repeated_texts)}\")\n",
    "display(repeated_texts.head(10))\n",
    "\n",
    "# =========================\n",
    "# LABEL CONFLICTS\n",
    "# =========================\n",
    "conflicts = (\n",
    "    df.groupby(TEXT_COL)[INTENT_COL]\n",
    "      .nunique()\n",
    "      .reset_index()\n",
    "      .query(f\"{INTENT_COL} > 1\")\n",
    ")\n",
    "\n",
    "print(f\"\\nâš ï¸ Intent conflicts: {len(conflicts)}\")\n",
    "display(conflicts.head(10))\n",
    "\n",
    "# =========================\n",
    "# DISTRIBUTIONS\n",
    "# =========================\n",
    "print(\"\\nğŸ“Š Intent distribution:\")\n",
    "display(df[INTENT_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Topic distribution:\")\n",
    "display(df[TOPIC_COL].value_counts())\n",
    "\n",
    "print(\"\\nğŸ“Š Sentiment distribution:\")\n",
    "display(df[SENTIMENT_COL].value_counts())\n",
    "\n",
    "# =========================\n",
    "# CLEANING\n",
    "# =========================\n",
    "clean_df = df.copy()\n",
    "\n",
    "# Remove short texts\n",
    "clean_df = clean_df[clean_df[\"text_len\"] >= MIN_TEXT_LEN]\n",
    "\n",
    "# Remove conflicting texts\n",
    "clean_df = clean_df[~clean_df[TEXT_COL].isin(conflicts[TEXT_COL])]\n",
    "\n",
    "# Remove duplicates (keep first)\n",
    "clean_df = clean_df.drop_duplicates(subset=[TEXT_COL], keep=\"first\")\n",
    "\n",
    "clean_df_chunk_2= clean_df.drop(columns=[\"text_len\"])\n",
    "\n",
    "print(\"\\nğŸ§¹ After cleaning:\")\n",
    "print(f\"Rows left: {len(clean_df)}\")\n",
    "print(f\"Unique texts: {clean_df[TEXT_COL].nunique()}\")\n",
    "\n",
    "# =========================\n",
    "# SAVE CLEAN DATA\n",
    "# =========================\n",
    "clean_df.to_csv(OUTPUT_CLEAN, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nğŸ’¾ Clean dataset saved to: {OUTPUT_CLEAN}\")\n",
    "\n",
    "# =========================\n",
    "# FINAL QUALITY SCORE\n",
    "# =========================\n",
    "quality_score = (\n",
    "    clean_df[TEXT_COL].nunique() / total_rows * 100\n",
    ")\n",
    "\n",
    "print(f\"\\nâ­ Dataset quality score: {quality_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27327ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "topic:\n",
      " topic\n",
      "availability      567\n",
      "delivery          511\n",
      "staff_behavior    396\n",
      "price             337\n",
      "insurance         284\n",
      "waiting_time      102\n",
      "prescription       87\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "sentiment:\n",
      " sentiment\n",
      "negative      826\n",
      "neutral       769\n",
      "positive      683\n",
      "frustrated      3\n",
      "mixed           2\n",
      "angry           1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "intent:\n",
      " intent\n",
      "Complaint    842\n",
      "Inquiry      766\n",
      "Praise       676\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "After merge:\n",
      "topic:\n",
      " topic\n",
      "delivery          613\n",
      "availability      567\n",
      "staff_behavior    396\n",
      "insurance         371\n",
      "price             337\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Dropped 0 rows outside allowed label sets.\n",
      "\n",
      "âœ… Saved: pharmacy_combined_fixed_merge.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "import os, yaml\n",
    "import pandas as pd\n",
    "\n",
    "EXPORT_DIR = \"saved_models\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Load\n",
    "df = pd.read_csv(\"pharmacy_combined.csv\").dropna(subset=[\"text\",\"intent\",\"topic\",\"sentiment\"]).copy()\n",
    "\n",
    "print(\"Before:\")\n",
    "print(\"topic:\\n\", df[\"topic\"].value_counts(), \"\\n\")\n",
    "print(\"sentiment:\\n\", df[\"sentiment\"].value_counts(), \"\\n\")\n",
    "print(\"intent:\\n\", df[\"intent\"].value_counts(), \"\\n\")\n",
    "\n",
    "# 2) Sentiment -> 3-class (match your project)\n",
    "sent_map = {\"angry\": \"negative\", \"frustrated\": \"negative\", \"mixed\": \"neutral\"}\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace(sent_map)\n",
    "\n",
    "# 3) Topic merge (your requested fix)\n",
    "topic_merge_map = {\n",
    "    \"waiting_time\": \"delivery\",\n",
    "    \"prescription\": \"insurance\",\n",
    "}\n",
    "df[\"topic\"] = df[\"topic\"].replace(topic_merge_map)\n",
    "\n",
    "print(\"After merge:\")\n",
    "print(\"topic:\\n\", df[\"topic\"].value_counts(), \"\\n\")\n",
    "\n",
    "# 4) (Optional) filter to allowed labels only (keeps things clean)\n",
    "allowed_topics = [\"availability\",\"delivery\",\"staff_behavior\",\"price\",\"insurance\"]  # now 5 topics\n",
    "allowed_sentiments = [\"negative\",\"neutral\",\"positive\"]\n",
    "allowed_intents = [\"Inquiry\",\"Complaint\",\"Praise\"]  # keep your dataset intent set\n",
    "\n",
    "before = len(df)\n",
    "df = df[\n",
    "    df[\"topic\"].isin(allowed_topics) &\n",
    "    df[\"sentiment\"].isin(allowed_sentiments) &\n",
    "    df[\"intent\"].isin(allowed_intents)\n",
    "].copy()\n",
    "print(f\"Dropped {before-len(df)} rows outside allowed label sets.\\n\")\n",
    "\n",
    "# 5) Save fixed dataset\n",
    "out_csv = \"pharmacy_combined_fixed_merge.csv\"\n",
    "df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ… Saved: {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47331ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent\n",
      "Complaint    842\n",
      "Inquiry      766\n",
      "Praise       676\n",
      "Name: count, dtype: int64\n",
      "topic\n",
      "delivery          613\n",
      "availability      567\n",
      "staff_behavior    396\n",
      "insurance         371\n",
      "price             337\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "negative    830\n",
      "neutral     771\n",
      "positive    683\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"intent\"].value_counts())\n",
    "print(df[\"topic\"].value_counts())\n",
    "print(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6907a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows: 0\n",
      "âœ… Saved: pharmacy_combined_fixed.csv\n",
      "intent\n",
      "Complaint    842\n",
      "Inquiry      766\n",
      "Praise       676\n",
      "Name: count, dtype: int64\n",
      "topic\n",
      "delivery          613\n",
      "availability      567\n",
      "staff_behavior    396\n",
      "insurance         371\n",
      "price             337\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "negative    830\n",
      "neutral     771\n",
      "positive    683\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pharmacy_combined.csv\").dropna(subset=[\"text\",\"intent\",\"topic\",\"sentiment\"]).copy()\n",
    "\n",
    "# sentiment -> 3-class\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace({\n",
    "    \"angry\": \"negative\",\n",
    "    \"frustrated\": \"negative\",\n",
    "    \"mixed\": \"neutral\",\n",
    "})\n",
    "\n",
    "# topic merge (your rules)\n",
    "df[\"topic\"] = df[\"topic\"].replace({\n",
    "    \"waiting_time\": \"delivery\",\n",
    "    \"prescription\": \"insurance\",\n",
    "})\n",
    "\n",
    "# keep Praise (don't drop it)\n",
    "allowed_intents = [\"Inquiry\", \"Complaint\", \"Praise\"]\n",
    "allowed_sent = [\"negative\",\"neutral\",\"positive\"]\n",
    "allowed_topics = [\"availability\",\"delivery\",\"staff_behavior\",\"price\",\"insurance\"]\n",
    "\n",
    "before = len(df)\n",
    "df = df[\n",
    "    df[\"intent\"].isin(allowed_intents) &\n",
    "    df[\"sentiment\"].isin(allowed_sent) &\n",
    "    df[\"topic\"].isin(allowed_topics)\n",
    "].copy()\n",
    "\n",
    "print(\"Dropped rows:\", before - len(df))  # should be 0 (or very small)\n",
    "df.to_csv(\"pharmacy_combined_fixed.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… Saved: pharmacy_combined_fixed.csv\")\n",
    "print(df[\"intent\"].value_counts())\n",
    "print(df[\"topic\"].value_counts())\n",
    "print(df[\"sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5545f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pharma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
